---
title: "Getting Started"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Getting Started}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  dpi = 150,
  collapse = TRUE,
  comment = "#>",
  out.width = "100%",
  fig.width = 8
)
library(ggplot2)
```


The `rcaaqs` package strives to automate the calculation of CAAQS metrics outlined by the Canadian Council of Ministers of the Environment. All calculations are derived from the [Guidance Document on Achievement Determination Canadian Ambient Air Quality Standards for Fine Particulate Matter and Ozone](https://www.ccme.ca/files/Resources/air/aqms/pn_1483_gdad_eng.pdf) and [Methods for SO~2~ and NO~2~ outlined by Environmental Reporting BC](https://github.com/bcgov/rcaaqs/blob/master/inst/EnvReportBC_NO2andSO2_Methods_Nov2016.pdf)

See the section ["Under the hood"](#under-the-hood) for a better idea of how `rcaaqs` performs the underlying calculations.


## CAAQS metrics

There are 7 CAAQS metrics for 4 different pollutants, in the `rcaaqs` package each has a corresponding function:

- `pm_24h_caaqs()` - Fine Particulate Matter (PM2.5) over 24 hours (3-yr rolling average)
- `pm_annual_caaqs()` - Fine Particulate Matter (PM2.5) over a year (3-yr rolling average)
- `o3_caaqs()` - Ozone over 8 hours (3-yr rolling average)
- `so2_3yr_caaqs()` - SO~2~ over 1 hour (3-yr rolling average)
- `so2_1yr_caaqs()` - SO~2~ over a year
- `no2_3yr_caaqs()` - NO~2~ over 1 hour (3-yr rolling average)
- `no2_1yr_caaqs()` - NO~2~ over a year

While the underlying calculations are different, in general the procedure to calculate any given metric is similar. Therefore we will focus on Annual PM2.5.

Let's start by loading some helpful packages

```{r}
# For plotting
library(ggplot2)  

# For data manipulation
library(dplyr)    
library(tidyr)

# For calculations
library(rcaaqs)
```

The `rcaaqs` package contains several sample data sets, let's take a look at the PM2.5 sample data:
```{r}
head(pm25_sample_data)
```


Calculating a CAAQS metric is straightforward. Just make sure you include grouping variables (i.e. station information in our case here)
```{r}
pm <- pm_annual_caaqs(pm25_sample_data, 
                     by = c("ems_id", "site"))
pm
```


Besides the actual CAAQS metric values (`metric_value`), there are several important columns.

**CAAQS details**

- `caaqs_year` - The year for which the CAAQS metric is compiled
- `min_year` & `max_year` - The first year and last years included in the rolling average (in this example)
- `n_years` - The total number of years included in a metric. Note that `metric_values` are NA for any year that has < 2 years included

**CAAQS values**

- `metric` - The name of the metric calculated
- `metric_value` - The actual CAAQS metric, calculated and rounded according to the documentation
- `caaqs` - The 'achievement' level of the CAAQS metric
- `mgmt` - The 'management' level of the CAAQS metric

**Data Exclusion**

- `excluded` - Whether any days were excluded due to Exceptional Events or Transboundary Flows (see below)

**Data completeness**

- `flag_daily_incomplete` - Whether any of the daily summaries were kept, but flagged as incomplete
- `flag_yearly_incomplete` - Whether any of the yearly summaries were kept, but flagged as incomplete
- `flag_two_of_three_years` - Whether the 3-yr rolling average is based on only 2 years

Note that in all cases values of `NA` indicate that flagging didn't apply to this metric (see CAAQS Documentation for more details)


## Excluding dates based on Exceptional Events or Transboundary Flows

First let's take a look at the daily averages, to do this, we need to re-run our CAAQS analysis, but retain intermediate data:

```{r}
pm <- pm_annual_caaqs(pm25_sample_data, 
                     by = c("ems_id", "site"),
                     return_all = TRUE)

pm
```

To explore any of these sub-data sets individually you can unnest the data (using the `unnest()` function from the `tidyr` package):

```{r}
pm_daily_avg <- unnest(pm, daily_avg)
pm_daily_avg
```

```{r, fig.asp = 0.8}
ggplot(data = pm_daily_avg, aes(x = date, y = avg_24h)) +
  geom_line() +
  facet_wrap(~ site)
```

Let's say, for illustration purposes, that all high values in the summer of 2012 were due to forest fires and we want to exclude them.

We'll `filter()` the daily data to just these dates and `select()` only the columns that reflect the grouping of our data and the dates.
```{r}
high_dates <- pm_daily_avg %>%
  filter(date >= as.Date("2012-05-01"),
         date < as.Date("2012-10-01"),
         avg_24h > 10) %>%
  select(ems_id, site, date)
high_dates
```

Now we can pass this on to our caaqs function with the `exclude_df` argument, which specifies the data frame, and the `exclude_df_dt` which specifies the name of the column holding the dates.

```{r}
pm_excl <- pm_annual_caaqs(pm25_sample_data, 
                          by = c("ems_id", "site"),
                          return_all = TRUE,
                          exclude_df = high_dates,
                          exclude_df_dt = "date")

pm_excl_caaqs <- unnest(pm_excl, caaqs)
pm_excl_caaqs
```

Note that the `excluded` column now has some `TRUE` values, reflect the fact that some dates in that metric have been excluded. (Note that excluding data in this manner does not influence the evaluation of data completeness).


We can also define excluded dates with date ranges, but here we must specify both start and end column names:

```{r}
high_dates <- data.frame(ems_id = "0310162",
                         site = "Port Moody Rocky Point Park",
                         start = as.Date(c("2012-06-11", "2012-07-01")),
                         end = as.Date(c("2012-06-25", "2012-08-14")))
high_dates

pm_excl <- pm_annual_caaqs(pm25_sample_data, 
                          by = c("ems_id", "site"),
                          return_all = TRUE,
                          exclude_df = high_dates,
                          exclude_df_dt = c("start", "end"))

pm_excl_caaqs <- unnest(pm_excl, caaqs)
pm_excl_caaqs
```

## Under the hood

To understand what's happening within the CAAQS functions we can take a look at this function flow chart:

```{r, echo = FALSE, fig.width = 12}
knitr::include_graphics(system.file('function_overview.png', package = 'rcaaqs'))
```

Each step from the documentation has a corresponding function (or functions) in the `rcaaqs` package, but most of these are hidden. The green boxes reflect the wrapper CAAQS functions that perform all the underlying steps. For example, the `o3_caaqs()` function performs all the steps outlined in the second green column.

## Airzones

We can match our data to an airzone by using the `assign_airzones()` function but you must have the following:

- A map file reflecting airzones, specifically a SpatialPolygonsDataFrame
- CAAQS data with latitude and longitude for each station/site

For the following examples, we'll use our `pm` CAAQS data, but only for 2013
```{r}
pm_caaqs <- unnest(pm, caaqs) %>%
  filter(caaqs_year == 2013)
```


We will get our map file from the [`bcmaps` package](https://github.com/bcgov/bcmaps) (note that you must also install the [`bcmaps.rdata package`](https://github.com/bcgov/bcmaps#usage)).


```{r}
library(bcmaps)
az <- bcmaps::airzones(class = "sp")
class(az)
az@data
```


We'll get our stations coordinates from an online list
```{r}
url <- "ftp://ftp.env.gov.bc.ca/pub/outgoing/AIR/Air_Monitoring_Stations/bc_air_monitoring_stations.csv"

stations <- readr::read_csv(url, na = "N/A") %>%  # Download csv file
  rename_all(tolower) %>%                         # Rename columns to lower case
  filter(ems_id %in% unique(pm$ems_id)) %>%       # Filter to ids in our pm data
  select(ems_id, latitude, longitude) %>%         # Select only the important columns
  mutate(latitude = as.numeric(latitude),         # Transform lat and lon to numeric
         longitude = as.numeric(longitude)) %>%
  distinct()                                      # Remove any duplicates

stations
```

Now we'll merge them into our CAAQS data

```{r}
pm_caaqs <- left_join(pm_caaqs, stations, by = "ems_id")
pm_caaqs
```

Now we have our airzones map and our station coordinates, we can match stations to airzones:

```{r}
pm_az <- assign_airzone(pm_caaqs, airzones = az, coords = c("latitude", "longitude"))
pm_az
```


```{r}
pm_az2 <- airzone_metric(pm_az)
pm_az2
```

## Mapping airzones


```{r, fig.width = 8, fig.asp = 1.5}
library(sp)
library(gridExtra)

az_plot <- spTransform(az, CRS("+proj=longlat")) %>%
  broom::tidy(az, region = "Airzone") %>%
  left_join(pm_az2, by = c("id" = "airzone"))

g1 <- ggplot(data = az_plot, aes(x = long, y = lat, group = group)) +
  theme(legend.position = c(0.85, 0.85)) +
  coord_map() +
  geom_polygon(aes(fill = caaqs)) +
  geom_path(colour = "black") +
  geom_point(data = pm_az, shape = 21, colour = "black",
             aes(x = lon, y = lat, fill = caaqs), 
             inherit.aes = FALSE) +
  scale_fill_manual(values = get_colours(type = "achievement"), drop = FALSE) +
  labs(title = "Achievement Status: PM2.5 Annual CAAQS")

g2 <- ggplot(data = az_plot, aes(x = long, y = lat, group = group)) +
  theme(legend.position = c(0.85, 0.85)) +
  coord_map() +
  geom_polygon(aes(fill = mgmt)) +
  geom_path(colour = "black") +
  geom_point(data = pm_az, shape = 21, colour = "black",
             aes(x = lon, y = lat, fill = mgmt), 
             inherit.aes = FALSE) +
  scale_fill_manual(values = get_colours(type = "management"), drop = FALSE) +
  labs(title = "Management Status: PM2.5 Annual CAAQS")

grid.arrange(g1, g2, ncol = 1)
```


